\documentclass[a4paper,12pt]{report}

\usepackage{GStyle} % Compile only with XeTeX!

\renewcommand{\GTitle}{Конспект лекций по дисциплине}
\renewcommand{\GCaption}{"Теория информации"}
\renewcommand{\GGTitle}{\vspace{-\baselineskip}}
\renewcommand{\GGCaption}{\vspace{-\baselineskip}}

\begin{document}

\maketitle
\maketoc

\section{Теория вероятности}





\subsection{Основные сведения из теории вероятности}





%\wdate{05.09.13}
\subsubsection{Введение}



%\paragraph{Классическое определение вероятности}


	Термин \term{информация} в курсе будет пониматься в узком научном смысле.

	\term{Теория информации} – специальная математическая дисциплина. Её содержанием является абстрактно формулируемые теоремы и модели. ТИ имеет обширное применение к теории передачи сообщений, записывающих устройств, матлингвистике, компьютерной технике.

	В самом общем виде теория информации понимается как теория передачи сигналов по линиям связи. Наиболее важное понятие ТИ –- сама информация. В нашей жизни большую роль играет информация и связанные с ней операции: передача, получение, обработка, хранение.

	Информация имеет две стороны: количественную и качественную. Иногда важно получение общего количества информации (количественная сторона), иногда важно конкретное содержание самой ИИ. Отметим, что переработка ИИ является технически сложной процедурой, которая усложняет разработку общей теории информации.

	Важнейшим этапом в открытии основных закономерностей ТИ были работы американского инженера-связиста, математика Клода Шеннона (1947-49гг). 

	Для вычисления количества информации была предложена т.н. \term{логарифмическая мера}. Понятие \term{количества информации} тесно связано с понятием энтропии как меры степени неопределённости. Приобретение информации сопровождается уменьшением неопределённости, следовательно, количество информации можно измерять количеством ''исчезнувшей неопределённости'' (энтропии).

	Теория информации является математической теорией, использующей понятия и методы теории вероятности.





\subsubsection{Вероятность. Случайные события и величины}

	Пусть производится серия из $N$ опытов, причём некоторое событие $A$ происходит в $N_a < N+1$. Тогда $h_n(A) = N_a/N $ называется частотой появления события $A$ в серии из $N$ опытов. 
	Известный факт: с ростом $N \quad h_n(A) \rightarrow p$ (постоянная $p$ - вероятность появления случайного события $A$).

	Наука, изучающая свойства вероятности и применение этого понятия называется \term{теория вероятности}.

	Событие, которое при выполнении некоторого комплекса условий обязательно выполняется называется \term{достоверным событием}.

	Событие, которое при выполнении некоторого комплекса условий не выполняется называется \term{невозможным событием}.

	\sample{Пример:} Выпадение определённого числа очков на грани игральной кости  - достоверное событие.

	Выпадение семи очков на грани игральной кости - невозможное событие.

	\term{Случайное событие} – событие, которое может произойти, а может и не произойти.


	\task{Задача:} В урне 10 шаров : 5 белых, 3 чёрных и 2 красных. Найти вероятность выпадения шара определённого цвета (шары одинаковы).

	\rtask{Решение:} Выписать случайные события:


	\begin{tabular}{rll}

		$A$ & –- \{вынутый шар белый\} & $P(A) = 5/10 = 1/2$;\\
		$B$ & –- \{вынутый шар чёрный\} & $P(B) = 3/10$;\\
		$C$ & –- \{вынутый шар красный\} & $P(C) = 2/10 = 1/5$.\\

	\end{tabular}


	\task{Задача:} Какова вероятность, что при бросании кости выпадет число очков,~кратное~3?

	\rtask{Решение:}\strut


	\begin{tabular}{l}

	Кратны $3\,\{3,6\}$.\\ 

	$N$ исходов $ = 6$.\\

	$P(A) = 2/6 = 1/3$.\\

	\end{tabular}


	\sstrut Общий принцип решения задач сводится к понятию равновероятности или равновозможности. (например, все грани кости одинаковы, и вероятность выпадения той или иной грани равна $1/6$).



\subsubsection{Классическое определение вероятности}

	Пусть из $N$ возможных исходов опыта случайное событие $A$ появляется $M$ раз. Тогда вероятность случайного события $A$ в модели с равновероятными исходами вычисляется по формуле $P(A) = M/N$ 

	Каждому опыту отвечает своя таблица вероятности. К примеру, в задаче с урнами и шарами таблица вероятности имеет вид: \strut


	\begin{tabular}{|l|c|c|c|}
	\hline
		События & A & B & C\\
	\hline	
		Вероятности & $P(A) = 1/2$ & $P(B) = 3/10$ & $P(C) = 1/5$\\
	\hline
	\end{tabular}


	\strut Можно сказать, что в опыте с бросанием кости число очков, выпадающих на грани является случайной величиной, которая может принимать одно из возможных 6 числовых значений в зависимости от случая.

	Итак, случайная величина –- числовая функция, принимающая то или иное числовое значение в зависимости от случая.

	Например, количество рождений в городе за год - случайная величина.





\subsubsection{Свойства вероятности. Сложение и умножение случайных событий.}





\paragraph{Несовместные и независимые случайные события.}

	Из определения вероятности вытекают основные свойства вероятности случайного события $A$:


	\begin{itemize}
	
	\item	$0 \leqslant P(A) \leqslant 1$.

	$P(A) = 1$ – достоверное событие;

	$P(A) = 0$ – невозможное событие.


	\item	Пусть опыт приводит к двум взаимоисключающим событиям или исходам $A$ или $B$. В этом случае B называют противоположным $A$ событием $(B = \bar A)$

		Пусть $P(A) = \frac{m}{n}$;

		Тогда $P(\bar A) = \frac{(n-m)}{n} 
				 = 1 - \frac{m}{n} 
				 = 1 - P(A) \Rightarrow P(A) 
				 = 1 - P(\bar A)$.

	Пусть случайное событие $A_1 \subset A$ влечёт появление события $A \Rightarrow P(A1) < P(A)$


	\item	\stitle{Правило сложения вероятностей для двух событий:}


		\begin{itemize}
		
		\item	Пусть $A$ и $B$ – несовместны. 

			Тогда $A \cap B = \eset$;

			$P(A) = \frac{m_1}{n}$; 

			$P(B) = \frac{m_2}{n}$;

			$P(A+B) = \frac{(m_1+m_2)}{n} 
				= \frac{m_1}{n} + \frac{m_2}{n} 
				= P(A) + P(B)$.

			Таким образом, $P(A+B) = P(A) + P(B)$.

			\medskip

			В примере с урной вероятность извлечь чёрный или белый шар равна 

			$P(A+B) = P(A) + P(B) 
				= \frac{1}{2} + \frac{3}{10} 
				= \frac{4}{5}$;

			\comm{Замечание:} Пусть некоторый опыт проиводит к появлению $K$ различных (взаимоисключающих) исходов: \strut


			\begin{tabular}{|l|c|c|c|c|}
			\hline
				Исходы & A1 & A2 & \sudots & An\\
			\hline
				Вероятности & P1 & P2 & \sudots & Pn\\
			\hline
			\end{tabular}	


			\strut Заметим, что бывают случаи, когда 

			$$
			  \sum_{i=1}^{k}P(A_i) 
			       = P(A_1+A_2+ \sudots +A_n) = 1
			$$

			В этом случае говорят, что события 
			   $A_1,A_2, \sudots ,A_n$ 
			составляют \term{полную} \linebreak \term{группу} случайных событий, то есть 
			   $A_1,A_2, \sudots ,A_n$
			попарно несовместны.

			$A_1,A_2, \sudots ,A_n : A_i \cap A_j 
			   = \eset \, \forall \, i,j: i \not= j$;
			если $A_1+A_2+ \sudots +A_n$ - достоверное событие.


		\item	Пусть $A$ и $B$ совместны. 
			$P(A+B) = P(A)+P(B)-P(AB)$,
			где $P(AB)$ – вероятность одновременного происхождения двух случайных событий $A$ и $B$.

		\end{itemize}			
	
	
	\stitle{Теорема сложения вероятности для совместных случайных событий.}
			 
			 (диаграмма Венна: $A = m_1; B = m_2, A \cap B = l$).

			$P(AB) = \frac{l}{n}$

			$P(A+B) = \frac{(m_1+m_2-l)}{n} 
				= \mbox{ (в $m_1$ и $m_2$ входит $l$) } 
				= \frac{m_1}{n} + \frac{m_2}{n} - \frac{l}{n}$

			События $A$ и $B$ называются \term{независимыми}, если результат выполнения события $A$ не связан с результатом события $B$. (извлечение двух чёрных шаров из разных урн – независимые события)


	\item	\stitle{Теорема умножения вероятности для двух независимых событий:}

		Если $A$ и $B$ независимы, то $P(AB) = P(A)*P(B)$

	\end{itemize}


	\sample{Пример 1:}  Какова вероятность при двух бросках монеты оба раза выпадет орёл?


	\begin{tabular}{ll}
	
		$P(AB) = \,\, ?$ & \\
	
		$A\mbox{\{орёл\}}$ & $ P(A) = \frac{1}{2}$;\\
	
		$B\mbox{\{решка\}}$ & $ P(B) = \frac{1}{2}$;\\
	
		& $P(AB) = \frac{1}{4}$.\\

	\end{tabular}

	
	\sample{Пример 2:} В колоде 52 карты, 4 масти, 2 козыря. Какова вероятность того, что взятая наугад карта 2 является тузом или козырем?


	\begin{tabular}{ll}
	
		$A\{\mbox{туз}\} \qquad$ & $P(A) = 1/13$;\\
	
		$B\{\mbox{козырь}\} \qquad$ & $P(B) = 1/4$;\\
	
		$P(AB) = 1/52$; & \\

		\multicolumn{2}{l}{$A$ и $B$ совместны, независимы.}\\

		\multicolumn{2}{l}{$P(A+B) = P(A) + P(B) - P(AB) = 1/13 + 1/4 - 1/52 = 4/13$}.\\

	\end{tabular}





%\wdate{19.09.13}

\subsubsection{Условная вероятность.}

	\sample{Рассмотрим пример:} В урне $M$ чёрных шаров и $N-M$ белых. 
	Случайное событие 
	\\$A$ \{извлечение чёрного шара\} и 
	\\$B$ \{извлечение чёрного шара из той-же урны после того, как из неё уже вынут один шаp\}

	$$
	  P(B|A) = \frac{(m-1)}{(n-1)}
	$$ 

	Поскольку, если событие $A$ имело место, то в урне осталось $M-1$ чёрных шаров.

	$$
	  P(B|\bar A) = \frac{m}{(n-1)}
	$$

	$\bar A : \{$первый вынутый шар - белый$\}$

	Вероятность события $B$ здесь разная. Вероятность, которую имеет событие $B$ в том, случае, когда известно, что событие $A$ имело место называется \term{условной вероятностью} события $B$ при условии выполнения события $A$.	

	$$
	  P(B/A) = P(B|A) = P_A(B)
	$$

	Условные вероятности можно вычислять аналогично вычислению безусловных вероятностей. 

	В случае если $A$ и $B$ независимы, $P(A|B) = P(A)*P(B)$. 

	В случае зависимости $P(AB) = P(A)*P(B|A) = P(B)*P(A|B)$. 

	В обоих случаях мы имеем правило умножения вероятностей. В одном случае для независимых событий, в другом для зависимых. Последнее соотношение часто кладут в определение условной вероятности. 

	$$
	  P(B|A) = \frac{P(AB)}{P(A)} \qquad 
	  P(A|B) = \frac{P(AB)}{P(B)}
	$$

	Из предыдущей формулы можем составить пропорцию: 
	
	$$
	  \frac{P(B|A)}{P(B)} = \frac{P(A|B)}{P(A)}
	$$

	Из определения условной вероятности вытекают ее основные свойства:


	\begin{enumerate}

	\item	$0 \leqslant P(B|A) \leqslant 1$, причём $P(B|A) = 1$ когда $A \subset B$; $B$ - достоверное случайное событие.

		$P(B|A) = 0 \Longleftrightarrow A, B$ несовместны, или известно, что $B$ – невозможное событие.

	
	\item	Пусть $B_1 \subset B$ (появление $B_1$ вызывает событие $B$). \; $P(B1|A) \leqslant P(B|A)$.


	\item	Если $B$ и $C$ несовместны $P(B+C|A) = P(B|A) + P(C|A)$ (теорема сложения вероятностей для несовместных событий)


	\item	$P(\bar B|A) =  1 - P(B|A)$

	\end{enumerate}


	\comm{Замечание:} Пусть имеется $K$ (и только $K$) попарно несовместных исходов некоторого опыта $A_1,A_2, \sudots ,A_k$, называемых гипотезами. Пусть некоторое случайное событие $B$ может произойти при выполнении одной из гипотез. Тогда очевидно, что $B = A_1B + A_2B + \sudots + A_kB$ (все события $A_iB$ несовместны, поэтому можно воспользоваться теоремой сложения вероятностей)

	$$
	  P(B) = P\left(\sum^k_{i=1}A_iB\right)
	       = \sum^k_{i=1}P(A_iB) 
	       = \sum^k_{i=1}\left(P(A_i)*P(B|A_i)\strut\right)
	$$

	Формула носит название формулы полной вероятности 

	$$
	  P(B) = \sum^k_{i=1}P(A_i)*P(B|A_i)
	$$

	
	\task{Задача: } Имеется 5 урн : в двух по одному белому и пять чёрных шаров; в одной – 2 белых, 5 чёрных; в двух – 3 белых, 5 чёрных шаров. Наудачу выбирается одна урна. Из неё извлекается один шар. Какова вероятность того, что шар белый?

	\rtask{Решение:} Выберем в качестве гипотез 3 способа \strut


	\begin{tabular}{ll@{\qquad}l}
	
		$A_1$ : \{Выбрана урна с 1 б.ш\} &  $P(A_1) = 2/5$ & $P(B|A_1) = 1/6$ \\
	
		$A_2$ : \{Выбрана урна с 2 б.ш\} & $P(A_2) = 1/5$ & $P(B|A_2) = 2/7$ \\
	
		$A_3$ : \{Выбрана урна с 3 б.ш\} & $P(A_3) = 2/5$ & $P(B|A_3) = 3/8$ \\
	
		$B$ = {извлечён белый шар} \qquad & & \\
		$P(B) = \frac{1}{6} * \frac{2}{5} + \frac{2}{7} * \frac{1}{5} + \frac{3}{8} * \frac{2}{5} = \frac{23}{84}$
	
	\end{tabular}





\subsubsection{Математическое ожидание случайной величины и его основные свойства}



	\paragraph{Введение.}

	Важнейшей числовой характеристикой $\xi$ является её математическое ожидание или среднее значение, вычисляемое по правилу $M\xi = \sum\limits^n_{i=1}x_ip_i)$, где $x_i$ – принимаемые $\xi$ значения, $p_i$ – вероятности их выпадения. 

	С помощью математического ожидания мы можем сравнивать между собой две случайные величины (например, из двух стрелков лучший тот, кто выбивает в среднем наибольшее число очков), однако встречаются задачи, в которых знание одного лишь $M\xi$ недостаточно. 


	\sample{Пример:} Пушка ведёт прицельный огонь по мишени, удалённой от пушки на расстояние $a$. Обозначим дальность полёта снаряда через $\xi$ километров; $M\xi = a$

	Отклонение $M\xi$ от $a$ свидетельствует о наличии систематической ошибки (производственный дефект, неправильный угол наклона). Ликвидация систематической ошибки достигается изменением угла наклона орудия. 

	Вместе с тем, отсутствие систематической ошибки ещё не гарантирует высокую точность стрельбы. Чтобы оценить точность надо знать, насколько близко ложатся снаряды к цели. 

	Как определить точность стрельбы и сравнить между собой качество стрельбы двух орудий?

	Отклонение снаряда от цели - $\xi - a$
	
	$M(\xi - a) = M\xi - a = a - a = 0$

	В среднем, положительные и отрицательные значения $M\xi$ сокращаются. Поэтому принято характеризовать разброс значений случайной величины математическим ожиданием квадрата её отклонения от своего математического ожидания. Полученное таким образом число называется дисперсией случайной величины $\xi$. 

	$D\xi = M(\xi-a)^2 = M[\xi-M\xi]^2$

	Ясно, что в случае орудий, ведущих стрельбу, лучшим следует считать орудие, у которого $D\xi$ будет наименьшей.

	Пусть $\xi$ характеризуется таблицей вероятностей \strut


	\begin{tabular}{|r|c|c|c|c|}
	\hline
		$x_i:$ & $x_1$ & $x_2$ & $\ldots$ & $x_n$\\
	\hline	
		$p_i:$ & $p_1$ & $p_2$ & $\ldots$ & $p_n$\\
	\hline
	\end{tabular}

	
	$$
	  M\xi = \sum^n_{i=1}x_ip_i;
	  \qquad
	  D\xi = M (\xi - M\xi)^2 
	       = \sum^n_{i=1}(x_i-M\xi)^2*p_i
	$$



\subsubsection{Определение математического ожидания}

	Пусть есть некоторое пространство, в котором имеется некоторое $\xi = \xi(\omega_i)$.

	$\omega_i$ – неразделимое событие (пример: исходы броска монеты); $\omega_i:(i=1,\bar n)$.

	Совокупность $\omega_i$ образует пространство элементарных событий
	$\Omega = \{ \omega_1, \omega_2, \sudots, \omega_n \}$

	\term{Математическим ожиданием} случайной величины $\xi$ называется число, обозначаемое $M\xi$ и равное 

	$$
	  M\xi = \sum_{\omega_i \in \Omega}\{(\omega_i)*P(\omega_i)\} 
	       = \sum^n_{i=1}\xi(\omega_i)*p(\omega_i)
	       \mbox{, где $p_i$ - элементарные вероятности.}
	$$

	Из определения математического ожидания вытекают следующие свойства:


	\begin{enumerate}

	\item	Аддитивность. $M(\xi + \eta) = M\xi + M\eta$. 

		Следствие $M\left(\sum\limits^n_{k=1}\strut\xi_k\right)=\sum\limits^n_{k=1}(M\xi_k)$.


	\item	$\forall C = const: M(C*\xi) = C*M\xi$. Совокупность свойств 1 и 2 даёт нам свойство линейности математического ожидания:

	$$
	  M(C_1\xi_1 + C_2\xi_2 + \sudots + C_n\xi_n) 
	    = C_1M(\xi_1) + C_2M(\xi_2) + \sudots + C_nM(\xi_n)
	$$


	\item	Математическое ожидание индикатора случайного события равно вероятности этого случайного события. 

	Индикатор $[\chi]$: $M\chi_A (\omega) = P(A)$ - случайная величина, принимающая 2 значения: 
		$
		  \chi_A(\omega) = \{1, \omega \in A \,|\, 0, \omega \not\in A\}
		$

		$$
		  \sum_{\omega \in A}P(\omega) = P(A)
		$$

		$$
		  M\chi_A(\omega) = \sum_{\omega \in A}1*p(\omega) + \sum_{\omega \not\in A}0*p(\omega)
		                  = \sum_{\omega \in A}1*p(\omega) = P(A).
		$$

	
	\item	Свойство монотонности $\xi \geqslant \eta \Rightarrow M\xi \geqslant M\eta$.

	\end{enumerate}


	Докажем вначале, что имеет место следующее свойство $\xi \geqslant 0 \Rightarrow M\xi \geqslant 0$ (при разложении по определению неотрицательны).

	$$
	  M\xi = \sum_\omega\xi(\omega)p(\omega) \geqslant 0.
	$$
	
	Применим полученное свойство:

	$$
	  \xi - \eta \ge 0 \Rightarrow 
	   M(\xi - \eta) \ge 0 \Rightarrow 
	   M\xi - M\eta \ge 0 \Rightarrow 
	   M\xi \ge M\eta.
	$$



\subsubsection{Формулы вычисления математического ожидания}

	Пусть $x_1,x_2, \sudots ,x_n$ –-  значения случайной величины $\xi$, принимаемые с вероятностями $p_1, \sudots ,p_i$. Тогда имеет место следующая формула для вычисления математического ожидания :

	$$
	  M\xi=\sum^n_{i=1}x_i*P(\xi=x_i)
	$$

	Чтобы доказать формулу будем исходить из того, что $\xi$ может быть представлена в виде линейной комбинации индикаторов случайных событий

	$$
	  \xi = \sum^n_{i=1}x_i*\chi_{A_i}(\omega)
	$$ $$
	  A_i \{\omega_i : \xi = x_i\}
	$$

	Левые и правые части соотношения совпадают. Применим к написанному равенству операцию математического ожидания: 

	$$	
	  M\left(\sum^n_{i=1}x_i\chi_{A_i}(\omega)\right) 
	    = \sum^n_{i=1}M\left(x_i\strut\chi_{A_i}(\omega)\right) 
	    = \sum^n_{i=1}x_iM\left(\strut\chi_{A_i}(\omega)\right) 
	    = \sum^n_{i=1}x_iP(\xi=x_i)	
	$$

	Рассуждая аналогично, нетрудно получить формулы вычисления математического ожидания от величин, представляющих собой функции случайных величин. 

	Пусть заданы $f(\xi),g(\xi,\eta)$.

	В этом случае 

	$$
	  M(f(\xi)) = \sum^n_{i=1}\left(f(x_i)*P(\xi=x_i)\right) 
	$$

	$$
	  M(g(\xi,\eta)) = \sum^n_{i=1}
	    \left(   
	      \sum^m_{j=1}g(x_i,y_j)*P
	        \left(
	          \xi=x_i,\strut\,\eta=y_i
	        \right) \!
	    \right) 
	$$

	Здесь $P(\xi,\eta)$ – совместная вероятность.


	\begin{enumerate}

	\item[5] Мультипликативное свойство математического ожидания

		Пусть $\xi,\eta$ - независимые случайные величины, то $M(\xi,\eta) =  M\xi * M\eta$

		Доказательство:

		$$
		  M(\xi,\eta) = \sum^n_{i=1}
		    \left(
		      \sum^m_{j=1}x_i*y_j*\strut P
		        \left(
		          \xi=x_i,\strut\eta=y_j
		        \right) \!
		    \right)
		$$

		Если $\xi,\eta$ независимы, то для них применима теорема умножения вероятности. 

		$$
		  P(\xi=x_i,\eta=y_j) 
		    = (\xi,\eta \mbox{ независимы})
		    = P(\xi=x_i)*P(\eta=y_j)
		$$
		
		$$
		  \sum^n_{i=1}
		    \left(
		      \sum^m_{j=1}x_i*y_j*\strut P(\xi=x_i)*P(\eta=y_j)
		    \right)
		  =
		$$
		
		$$
		  = \sum^n_{i=1}x_i*P(\xi=x_i)  \, * \, 
		    \sum^m_{j=1}y_i*P(\eta=y_j) 
		  = M\xi*M\eta
		$$

	\end{enumerate}


	\comm{Замечание:} Все написанные формулы имеют место, если вероятностное пространство конечно, т.е. число элементарных событий конечно $\omega_i = (1,\bar n)$. 

	В случае, если вероятностное пространство счётно, количество элементарных сообщений бесконечно, тогда для случайной величины 
	$
	  \xi(\omega), 
	  \omega \in \mbox{(счетное вероятностное пространство)}
	$
	имеют место следующие формулы:

	$$
	  \omega_i, i = [\overline{1,\strut\infty}]
	$$

	$$
	  M\xi = \sum^\infty_{i=1}\left(x_i*P(\xi=x_i)\right)
	$$

	$$
	  Mf(\xi) = \sum^\infty_{i=1}\left(f(xi)*P(\xi=x_i)\right)
	$$

	В формулах справа стоят ряды. Чтобы математические ожидания существовали надо, чтобы эти ряды сходились. Ряд сходится, если он имеет конечную сумму.

	
	\task{Задача:} Вычислить $M\xi$, распределённой по закону Пуассона. $P(\xi=k)=(a^k/k!)e^{-a}$,
	  где $k=\{0,1,2,3,4, \sudots ,\infty\}; \; a>0$ – заданный заранее характер распределения. 

	\rtask{Решение:} 

	$$
	  M\xi = \sum^\infty_{k=0}k*\frac{(a^k*e^{-a})}{k!}
	       = e^{-a}\sum^\infty_{k=0}k*\frac{(ka^k)}{k!}
	       =
	$$ $$
	       = e^{-a}\sum^\infty_{k=0}\frac{(k*a^{k-1}a)}{(k-1)!}
	       = e^{-a}a\sum^\infty_{s=0}\frac{a^s}{s!}\mbox{\scriptsize\quad (формула Маклорена)}
	       = e^{-a}ae^a = a
	$$ 
	
	

	Математическое ожидание случайной величины,  распределённой по закону Пуассона с параметром распределения $a$ равно этому параметру распределения.

%\wdate {03.10.13}

	Если $\xi$ непрерывна, её закон распределения определяется плотностью распределения $ f_\xi(x) \ge 0 \Rightarrow M\xi =  \int\limits_{-\infty}^{\infty} x f_\xi(x) dx$. Если имеется функция $g(\xi), \; g(\xi,\eta)$, то математическое ожидание вычисляется по формулам:

	$$
	  M_{g_\xi} = \int\limits_{-\infty}^{\infty} g(x) f_\xi(x) dx
	$$

	$$
	  M(\xi,\eta) = \iint\limits_{-\infty}^{\quad\infty} g(x,y) f_{\xi\eta}(x,y) dx \, dy
	$$

	где $f(\xi,\eta)$ - плотность совместных случайных величин.

	Эти математические ожидания существуют, если все написанные несобственные интегралы сходятся.


	\task{Пример: } вычислить математическое ожидание $\xi$, равномерно распределённое $\sim$ %прке F..B
	
	\rtask{Решение: } 

		$$
		  f_\xi (x)= \frac{1}{b-a},
		    a \le x \le b \; | \; 0,x \in \mbox{\small в остальных случаях}
		$$

		$$
		  M_\xi = \int\limits_{-\infty}^\infty x f_\xi(x) dx
		        = \frac{1}{b-a} \int\limits_a^b x dx 
		        = \left. \frac{x^2}{2(b-a)} \right|^b_a 
		        = \frac{a+b}{2}
		$$


	\task{Пример 2: } вычислить математическое ожидание случайной величины $\xi$, распределённой нормально (по закону распределения Гаусса) 

		$$ f_\xi(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-a)^2}{2\sigma^2}} 
		            = \frac{1}{\sqrt{2\pi}\sigma} \int\limits^\infty_{-\infty} (x-a) e^{-\frac{(x-a)^2}{2\sigma^2}} dx 
		             +
		$$ $$
		             + \frac{a}{\sqrt{2\pi}\sigma} \int\limits^\infty_{-\infty} (x-a) e^{-\frac{(x-a)^2}{2\sigma^2}} dx 	\; \mbox{\scriptsize (интеграл Лапласа)}
		            = 0 + \frac{a}{\sqrt{2\pi}\sigma} \sqrt{2\pi}\sigma 
		            = a
		$$

	\rtask{Вывод: } Распределение случайной величины, распределённой нормально, равно параметру распределения.





\subsubsection{Дисперсия случайной величины и её основные свойства.}

	Дисперсия $D\xi$ - число, определяемое формулой $D\xi = M(\xi-M\xi)^2 \; (1)$, т.е. дисперсия представляет собой квадрат разности случайной величины и её математического ожидания. Другое название - квадрат среднеквадратического отклонения. 

	Часто в прикладных задачах вместо $D$ рассматривают величину $\sqrt{\!D}$, называемую среднеквадратическим отклонением

	Формулу (1) можно продолжить, тогда мы получим 
	  $$
	    D_\xi = M\left(\xi^2- \strut 2\xi M\xi + (M\xi)^2\right) 
	          = M^2\xi - 2M\xi + 2M\xi + (M\xi)^2 
	          = M^2\xi - (M_\xi)^2,
	  $$
	откуда $(2) \quad D\xi = M^2\xi + (M\xi)^2$


	\begin{enumerate}
	
	\item Пусть $\xi$ - дискретная величина, принимающая значения $x_1, \sudots, x_n$ с вероятностями $p_1, \sudots ,p_n$

	$$
	  D\xi = \sum^n_{k=1}(x_k M\xi)^2*p_k = (2)
	       = \sum^n_{k=1}(x^2_k*p_k)^2 - (M\xi)^2
	$$

	\item Пусть $\xi$ - непрерывная случайная величина, значит может быть определена функция $f_\xi(x)$. 
	
	$$
	  D\xi = (1) = \int\limits_{-\infty}^\infty x^2 f_\xi(x) dx - (M\xi)^2
	$$

	\end{enumerate}


	Дадим механическую интерпретацию математического ожидания и дисперсии случайной величины. Будем представлять закон распределения вероятностей $p_k = P(\xi = x_k), \sum\limits^n_{k=1}p_k = 1$ случайной величины $\xi$, как закон распределения единичной массы на прямой: в точках $x_k$ сосредоточены массы $p_k$ : 
	
	$$
	  ---\frac{x_1}{p_1}---\frac{x_2}{p_2}- \cdot \cdot \cdot -\frac{x_n}{x_n}--->x
	$$
	
	Тогда 
	
	$$
	  M\xi = \sum^n_{k=1} x_k P(\xi=x_k) \mbox{ - центр тяжести СМАТ}	
	$$ 

	$$
	  D\xi = \sum^n_{k=1} (x_k - M_\xi)^2 * p_k \mbox{ - момент инерции относительно начала координат}
	$$

 	\task{Пример: } $D\xi = ?, \; f_\xi(x) = e^{-\frac{(x-a)^2}{2\sigma^2}}$

 	\rtask{Решение: } 
 	
 	$$
 	  D\xi = \int\limits^\infty_{-\infty}(x-M\xi)^2 f_\xi(x) dx
 	       = \frac{1}{\sqrt{2\pi}\sigma}\int\limits^\infty_{-\infty} (x-a)^2 e^{-\frac{(x-a)^2}{2\sigma^2}} dx
 	       = 
 	$$
 
 	Произведём замену переменной по формуле $y = \frac{x-a}{\sigma}, \; x - a = \sigma y, \; dx = \sigma dy$
 
 	$$
 	   = \frac{1}{\sqrt{2\pi}\sigma} \int\limits_{-\infty}^\infty \sigma^2 e^{-\frac{y^2}{2}} \sigma dy 
 	   = \frac{\sigma^2}{\sqrt{2\pi}}  \int\limits _{-\infty}^\infty (-y ) de^{-\frac{y^2}{2}} 
	%   =
 	% $$ $$
 	   = \frac{\sigma^2}{\sqrt{2\pi}} \left( \left. -ye^{-\frac{y^2}{2}} \right|^{+\infty}_{-\infty} \strut 
 	     + \int\limits_{-\infty}^\infty e^{-\frac{y^2}{2}} dy \right)
 	   = \sigma^2
 	 $$
 
	 Вывод: дисперсия нормального распределения случайной величины равна второму параметру распределения $(\sigma^2)$: $M_\xi = a; \; D_\xi = \sigma^2$

	


	
\subsubsection{Свойства дисперсии}


	\begin{enumerate}

	\item	Дисперсия неотрицательна: $D_\xi \ge 0.$ $D_\xi = 0 \Longleftrightarrow \xi = const$. 
		
		Доказательство: $D\xi = M(\xi-M\xi)^2 \ge 0 - $ по свойству монотонности.
		
		Пусть $\xi = c = const$.
		
		Тогда $D_c = M(c-M_c)^2 =(c - c)^2 = 0$.


	\item	Если $a = const$, то дисперсия $D(a\xi) = a^2 D\xi$. 
	
		Доказательство: 
		
		$D(a\xi) = M(a\xi - Ma\xi)^2
		         = M(a\xi - a M\xi)^2
		         = M[a^2 (\xi-M\xi)^2]
		         = a^2 M(\xi - M\xi)
		         = a^2 D\xi
		$
		

	\item	Если $\xi,\eta$ независимы, то 
		$$
		  D(\xi + \eta) = M\left(  \xi \strut + \eta - M(\xi +\eta)    \right)^2 
		                = M\left( (\xi - M\xi) \strut + (\eta - M\eta) \right)^2
		                =
		$$ $$		                
		                = M(\xi - M\xi)^2 + 2(\xi-M\xi)(\eta - M\eta) + M(\eta - M\eta)^2
		                =
		$$ $$
		                = M(\xi - M\xi)^2 + 2M\left( (\xi - M\xi) \strut * (\eta - M\eta)\right) 
		                  + M(\eta - M\eta)^2
		                = D\xi + D_\eta
		$$
	
	\end{enumerate}
	
	
	
	

\subsection{Энтропия и информация}

\subsubsection{Энтропия как мера неопределённости}

	Для практики важно уметь численно оценивать степень неопределённости самых разнообразных опытов, чтобы иметь возможность их сравнивать. 
	
	Начнём с рассмотрения опытов имеющих $K$ равновероятных исходов. Степень неопределённости каждого такого опыта определяется числом $K$. При $K = 1$ исход опыта не является случайным. При большом значении $K$ предсказание результата опыта становится затруднительным.
	
	Таким образом, искомая численная характеристика степени неопределённости должна зависть от $K$, т.е быть функцией $f(k); \; f(1)=0$; при возрастании аргумента, функция должна возрастать. Для более полного определения функции $f(k)$ необходимо предъявить к ней дополнительные требования. 
	
	Рассмотрим сложный опыт $\alpha\beta$, состоящий в одновременном выполнении опытов $\alpha$ и $\beta$. Неопределённость выполнения сложного опыта больше неопределённости опыта $\alpha$, т.к. к его неопределённости надо добавить неопределённость опыта $\beta$. Поэтому естественно считать, что \term{степень неопределённости} опыта $\alpha\beta$ равна сумме неопределённостей, характеризующих $\alpha$ и $\beta$.
	
	Пусть $\alpha \beta$ имеет $k*l$ равновероятных исходов, $k\alpha, \; l\beta$. Приходим к следующему условию, которму должна удовлетворять функция $f(kl) = f(k) + f(l)$. Последнее условие наталкивает на мысль принять за меру неопределённости опыта, имеющего K равновероятных исходов число $\log k$: $\log(kl) = \log k + \log l$. Такое определение меры неопределённости согласуется с первоначальными условиями, что $f(1) = \log1 = 0; f(k) \mbox{ - возрастающая функция}$. Можно доказать, что логарифмическая функция является единственной, удовлетворяющей этим условиям.

%/next

 	\comm{Замечание: } отметим, что выбор основания логарифма большой роли не играет, поскольку в силу известной формулы перехода можем написать $\log_ba = \log_ca/\log_cb \Rightarrow \log_bk = \log_ba*log_ak$ сводится к домножению на константу, т.е. равносилен простому изменению \term{единицы измерения} степени неопределённости. Обычно за меру степени неопределённости берут логарифмы при основании 2: $log_2k = logk$, причём основание 2 не фиксируют. Т.е. за единицу измерения степени неопределённости принимают неопределённость опыта, имеющего 2 равновероятных исхода: $\log_22 = 1$ бит. Везде далее будем пользоваться двоичными единицами измерения. 

	Таблица вероятности для опыта, имеющего $K$ равновероятных исходов:
	

	\begin{tabular}{|l|c|c|c|c|}
	\hline
		$\alpha$ &&&&\\
	\hline
		Исходы & $A_1$ & $A_2$ & $\sudots$ & $A_k$ \\
	\hline
		Вероятности& $\frac{1}{k}$& $\frac{1}{k}$ & $\sudots$ & $\frac{1}{k}$\\
	\hline
	\end{tabular}


	Поскольку при наших допущениях неопределённость равна $f(k) = \log k$. В этом случае каждый отдельный исход вносит неопределённость $\frac{1}{k}$. $\frac{\log k}{k}= \frac{1}{k} \log k = -\frac{1}{k}\log\frac{1}{k}$.
	
	В самом общем случае опыт имеет следующую таблицу вероятности:


	\begin{tabular}{|l|c|c|c|c|}
	\hline	
		$\alpha$&&&&\\
	\hline
		Исходы & $A_1$ & $A_2$ & $\sudots$ & $A_k$ \\
	\hline
		Вероятности & $P(A_1)$ & $P(A_2)$ & $\sudots$ & $P(A_k)$ \\
	\hline
	\end{tabular}

	
	Для опыта общая мера неопределённости равна 
	  $ -p(A_1)  \log p(A_1) - p(A_2)  \log p(A_2) - \sudots - p(A_k)  \log p(A_k) = H(\alpha) \mbox{ - энтропия опыта $\alpha$}$

	Рассмотрим некоторые свойства энтропии $H(\alpha)$:


	\begin{enumerate}
	
	\item $H(\alpha) \ge 0$ 

	Доказательство:
	
	$ -p(A) \log p(A) \ge 0 \mbox{ (\scriptsize множители $\in$ промежутку $(0 \le p(A) \le 1)$ ) } $

	$ -p(A) \log p(A) = 0 \Longleftrightarrow \{ p=0; p=1 \}$

	В случае, если опыт имеет $K$ попарно несовместных исходов, то $H(\alpha) = 0$ равносильно тому, что один исход - достоверное событие, а все другие - невозможны, так как $\left(p(A_1)\strut+\sudots+p(A_k) = 1\right)$.	Это обстоятельство хорошо согласуются с величиной $H(\alpha)$ -  только в этом случае опыт вообще не содержит неопределённости.


	\item Из всех опытов c $K$ исходами самым неопределённым является опыт опыт с $K$ равновероятными исходами. Можно показать, что имеет место неравенство 
	
	$H(\alpha) = - p(A_1) \log p(A_1) - \sudots - p(A_k) \log p(A_k) \le H(\alpha_0)$
	
	$H(\alpha_0) = \log k = -\frac{1}{k} - \sudots -\frac{1}{k}$. 
	
	Равенство достигается при равных вероятностях $P(A_i); \; i = [\overline{1,k}]$
	
	\end{enumerate}


	\task{Пример: } Имеется две урны с 20-ю шарами каждая. Первая - 10 белых, 5 чёрных, 5 красных. Вторая - 8 белых, 8 чёрных, 4 красных.

	Из каждой урну вынимают по 1 шару. Исход какого из двух опытов следует считать более неопределённым?
	
	\rtask{Решение: } Обозначим опыты как А1 и A2.

	A1

	\begin{tabular}{|l|c|c|c|}
	\hline
		Исходы & Бел & Чёр & Крас \\
	\hline
		Вероятности & 1/2 & 1/4 & 1/4 \\
	\hline
	\end{tabular}

	A2

	\begin{tabular}{|l|c|c|c|}
	\hline
		Исходы & Бел & Чёр & Крас \\
	\hline
		Вероятность & 2/5 & 2/5 & 1/5 \\
	\hline
	\end{tabular}

	Энтропия опыта A1: 
		$H(\alpha_1)= - \frac{1}{2} \log \frac{1}{2} 
		              - \frac{1}{4} \log \frac{1}{4}
		              - \frac{1}{4} \log \frac{1}{4}
		            = - \frac{1}{2} * 1 
		              - \frac{1}{2} * (-2) 
		            = - \frac{1}{2} + 1
		            = 1,5 \mbox{бита}$.
	
	Энтропия опыта A2:
		$H(\alpha_2)= - \frac{2}{5} \log \frac{2}{5}
		              - \frac{2}{5} \log \frac{2}{5}
		              - \frac{1}{5} \log \frac{1}{5}
		            = - \frac{4}{5}(\log 2-\log 5) - \frac{1}{5} (\log 1 - \log 5)
		            = - 0.8 + - \frac{4}{5} \log 5 + \frac{1}{5} \log 5 
		            = - 0.8 + \log 5 = 1,52 \mbox{ бита.}
		$

	\rtask{Вывод: } Если оценивать степень неопределённости опыта его энтропией, то исход второго опыта более неопределённый, нежели первого.
	
	\stitle{Историческая справка} % =)

	Исторически первые шаги к введению понятия энтропии были сделаны в 1928 году американским инженером-связистом Хартли, предложившим характеризовать степень неопределённости опыта c К различными исходами числом $\log k$. Предложенная им мера степени неопределённости иногда бывает удобна в некоторых практических задачах, но часто оказывается малопоказательной, поскольку полностью игнорирует различие между характером имеющихся исходов. Поэтому почти невероятному исходу у Хартли придаётся такое-же значение, как и исходу весьма вероятному. Однако, он считал, что различия между отдельными исходами определяются в первую очередь "психологическими факторами" и должны учитываться лишь психологами, но не инженерами или математиками.
	
	Ошибочность точки зрения Хартли была показана другим американским инженером~-~математиком К. Шенноном. Он предложил принять в качестве меры неопределённости опыта с $K$ различными исходами $A_1,\sudots,A_k$ величину
	
	 $H(\alpha) = - p(A_1) \log p(A_1) - \sudots - p(A_k \log p(A_k)$. 
	
	Иначе говоря, исходу $A_i$ следует приписать неопределённость, равную $- \log p(A_i)$. В качестве неопределённости всего опыта $H(\alpha)$ принимается среднее значение случайной величины (математическое ожидание), равное $H(\alpha) \xi $ ,где $\xi \mbox{ принимают значения } - \log p(A_i) \mbox { с вероятностями } p(A_i)$.

	Таким образом, загадочные "психологические факторы" учитываются с помощью использования понятия вероятности, имеющего чисто математический, а точнее статистический характер.
	
	Использование величины $H(\alpha)$ в качестве меры неопределённости опыта $A$ оказалось полезным во многих областях, а особенно в теории передачи сообщений по линиям связи.

\subsubsection{Энтропия сложных событий. Условная энтропия}

	Условная энтропия. Пусть имеются два независимых опыта $A, B$ с таблицей вероятностей $A_1, p(A_1); \sudots ;A_k, p(A_k); \quad B_1, p(B_1); \sudots ;B_l, p(B_l)$.
	
	Рассмотрим сложный опыт $\alpha \beta$, когда осуществляются оба опыта одновременно, имеющий $k*l$ исходов ($A \times B$ - декартово произведение).

	$A_1B_1 : \alpha = A_1; \beta = B_1$

	Очевидно, что неопределённость опыта $\alpha \beta$ больше неопределённости каждого из опытов, из-за осуществления обоих опытов. Поэтому имеет место соотношение $H(\alpha\beta) = H(\alpha)+H(\beta)$. Написанное равенство называется правилом сложения энтропии для опытов $\alpha$ и $\beta$.

	Для доказательства этого равенства рассмотрим выражение 
	
	$$
	  H(\alpha\beta) = 
	    - p(A_1B_1) \log p(A_1 B_1) 
	    - \sudots 
	    - p(A_kB_l) \log p(A_k B_l)
	$$ 
	
	$$
	 \alpha, \beta \mbox{ - независимы, следовательно } 
	   p(A_iB_j) = p(A_i) * p(B_j) \Rightarrow
	$$
	
	$$
	  \log p(A_iB_j) 
	   = \log p(A_i) p(B_j) 
	   = \log p(A_i) + \log p(B_j).
	$$



%\wdate{17.10.13}

	%Реферат - 5-10стр.
	
	Предположим далее, что $\alpha$ и $\beta$ - зависимые опыты (пример: $\alpha$, $\beta$ - последовательные извлечения двух шаров из одной урны.) Постараемся выяснить, чему равна энтропия сложного опыта $\alpha \beta$ в этом случае. 
	
	Здесь уже нельзя заменить $p(A_1 B_1) , p(A_1 B_2), \sudots $ произведением вероятностей, а необходимо использовать условную вероятность $p(A_1 B_1) = p(A_1) * p(B_1|A_1)$
	
	В этом случае можно доказать следующую формулу:
	
	$
	  H(\alpha\beta) = H(\alpha) +
	   \left[ 
	      p(A_1) * H(\beta|A_1) 
	    + p(A_2) * H(\beta|A_2)
	    + \sudots 
	    + p(A_k) * H(\beta|A_k) 
	   \right] 
	 (*)
	$ , где $H(\beta|A_i)$ - условная энтропия опыта $\beta$ при условии, что значение опыта $\alpha$ равно $A_i$.

	$
	  H(\beta|A_i) = 
	   - p(B_1|A_i) \log p(B_1|A_i) 
	   - p(B_2|A_i) \log p(B_2|A_i)
	   - \sudots 
	   - p(B_e|A_i) \log p(B_e|A_i) 
	  (**) 
	$
	
	Это выражение представляет собой энтропию опыта $\beta$ при условии, что имеет место событие $A_i$.
	
	$$
	\left\{
	 \begin{aligned}
	   H(\alpha,\beta) & = H(\alpha) + H(\beta) \quad (\mbox{ для независимых } \alpha, \beta)\\
	   H(\alpha,\beta) & = H(\alpha) + [\sudots](*) \quad (\mbox{ для зависимых }   \alpha, \beta)
	 \end{aligned}
	\right.
	$$

	Первый член последнего выражения $(*)$ - энтропия опыта $\alpha$. Что же касается второго - он есть математическое ожидание случайной величины, принимающей с вероятностями $p(A_1), \sudots ,p(A_k)$ значения $H(\beta | A_1), \sudots, H(\beta | A_k)$, то есть значения, равные условной энтропии опыта $\beta$, при условии, что опыт $\alpha$ имеет исходы $\alpha : A_1, \sudots, A_k$. Это среднее значение естественно назвать \term{условной энтропией} выполнения опыта $\beta$ при условии выполнения опыта $\alpha$,

	$$ 
	  H(\beta|\alpha) = [\sudots](*) = p(A_1) H(\beta|A_1) + p(A_2) H(\beta|A_2) + \sudots + p(A_k) H(\beta|A_k)
	$$

	Тогда соотношение $(*)$ переписывается как $H(\alpha\beta) = H(\alpha) + H(\beta|\alpha) (*);$ $ \alpha, \beta \mbox{ - зависимы}$.

	Это и есть общее правило для определения энтропии сложного опыта $\alpha\beta$. Его также можно назвать правилом сложения энтропии, для \term{зависимых} опытов $\alpha\beta$.
	
	Укажем основные свойства условной энтропии:


	\begin{enumerate}
	
	\item	$H(\beta|\alpha) \ge 0$.
	
	\item	$p(A_1), \sudots, p(A_k) \not = 0$ (опыт имеет к штук исходов).
		
		Тогда $H(\beta|\alpha) = 0 \Longleftrightarrow H(\beta|A_1) = \sudots = H(\beta|A_k) = 0$, т.е. при любом исходе опыта $\alpha$ результат опыта $\beta$ полностью определён, и при этом имеем 
		$H(\alpha\beta) = H(\alpha)$.
		
		Если $\alpha$ и $\beta$ \term{независимы}, то тогда $H(\beta|\alpha) = H(\beta)$, и $H(\alpha\beta) = H(\alpha)+H(\beta)$.
	
	\item	Во всех случаях условная энтропия $H(\beta|\alpha)$ заключается между $0$ и $H(\beta)$:	
		
		$0 \le H(\beta|\alpha) \le H(\beta)$. 

		Таким образом случаи, когда исход $\beta$ полостью предопределяется исходом $\alpha$ и когда опыты $\alpha$ и $\beta$ независимы, являются в определённом смысле крайними.	

	\item 	Условная энтропия. 
		$$
		  H(\alpha\beta) = H(\beta\alpha) \Rightarrow 
		    H(\alpha) + H(\beta|\alpha) 
		     = H(\beta) + H(\alpha|\beta) \Rightarrow	     
		$$ $$ \Rightarrow
		    H(\beta|\alpha)
		     = H(\alpha|\beta)(.) + H(\beta) - H(\alpha)
		$$
		
		$H(\alpha|\beta) = 0$ (исход опыта $\beta$ полностью определяет опыта $\alpha$
		
		$H(\beta|\alpha) = H(\beta) - H(\alpha)$
		
	\end{enumerate}

	
	\task{Задача: } %(будет на зачёте)
		Задача о болезненной реакции. 
		
		Известно, что некоторой болезнью в среднем болеют 2 человека из 100. Для выявления больных используется определённая реакция, которая всегда оказывается положительной в том случае, когда человек болен. Если же человек здоров, то она столь же часто бывает положительной, как и отрицательной. Пусть опыт $\beta$ состоит в определении того болен или здоров человек, а опыт $\alpha$ - в определении результата указанной реакции. Спрашивается, какова будет энтропия $H(\beta) = ?$ опыта $\beta$ и условная энтропия $H(\beta|\alpha) = ?$.
	
	\rtask{Решение:} Очевидно, что $\beta$ имеет 2 исхода: $\beta : \{B_1\mbox{ - здоров}; \; B_2\mbox{ - болен}\}$.
	
	$p(B_1) = 0.98; \quad p(B_2) = 0.02$.
	
	$H(\beta) = - 0.98 \log 0.98 - 0.02 \log 0.02 \approx 0.14 \mbox{бит}.$
	
	$H(\beta) \approx 0.14 бит.$
	 
	Рассмотрим опыт $\alpha$: \; $\alpha : {A_1 - \mbox{ положительная реакция}; \; A_2 - \mbox{ отрицательная реакция}}$

	$  p(A_1) = p(\frac{B_1}{2} + B_2) 
	          = p(\frac{B_1}{2}) + p(B_2)
	          = 0.49 + 0.02
	          = 0.51
	$.

	$  p(A_2) = p(\frac{B_1}{2}) 
	          = 0.49
	$.

	$
	  \alpha = A_1 : p(B_1|A_1)
	         = \frac{p(B_1 A_1)}{p(A_1)}
	         = \frac{0.49}{0.51}
	         = \frac{49}{51}.
	$
	
	$
	  \alpha = A_2 : p(B_2|A_1) 
	         = \frac{p(B_2 A_1)}{p(A_1)} 
	         = \frac{0.02}{0.51} 
	         = \frac{2}{51}. 
	$
	
	Пользуясь этими данными мы можем найти условную энтропию $H(\beta)$ при выполнении события $A_1$

	$$
	  H(\beta|A_1) = - \frac{49}{51} \log \frac{49}{51}
	                 - \frac{2}{51}  \log \frac{2}{51}
	         \approx 0.24 \mbox{ бит.}
	$$
	
	При $\alpha = A_2 \Rightarrow \beta = B_1; \; H(\beta|A_2) = 0$, т.е. мы с уверенностью можем утверждать, что человек здоров, и опыт $\beta$ имеет исход $B_1$.
	
	Таким образом, условная энтропия $\beta$ при условии осуществления $\alpha$ будет равна 
	
	$$
	  H(\beta) ~= 0.14 бит | sys 	H(\beta|A_1) \approx 0.045
					H(\beta|A_2) = 0 \sim \sim
	$$
				
	$$
	  H(\beta|\alpha) = p(A_1)H(\beta|A_1) + p(A_2)H(\beta|A_2) 
	            \approx 0.51 * 0.24 + 0.49 * 0
	                  = 0.12 \mbox{ бит.}
	$$
	
	Иначе говоря, выполнение опыта $\alpha$ уменьшает неопределённость опыта $\beta$ на $0.002$ бита.
	
	
	
	\subsubsection{Понятие об информации.}
	
	Вернёмся вновь к величине $H(\beta)$, характеризующей степень неопределённости опыта $\beta$. Равенство этой величины $0$ означает, что исход опыта $\beta$ заранее известен. Большее или меньшее значение числа $H(\beta)$ отвечает большей или меньшей проблематичности определения результата опыта $\beta$. Какое-либо измерение или наблюдение в виде опыта $\alpha$, предшествующее $\beta$ может ограничить количество возможных исходов опыта $\beta$, и тем самым уменьшить степень его неопределённости: так, к примеру степень неопределённости опыта, состоящего в нахождении самого тяжёлого из $3$ грузов уменьшается после сравнения на весах двух из них. 

	Для того, чтобы результат измерения(наблюдения) $\alpha$ мог сказаться на последующем опыте $\beta$ необходимо, чтобы $\alpha$ \term{не был известен заранее.} Поэтому, $\alpha$ можно рассматривать как вспомогательный опыт, также имеющий несколько допустимых исходов. 
	
	Тот факт, что осуществление $\alpha$ уменьшает степень неопределённости $\beta$ отражается в неравенстве, где условная энтропия $H(\beta|\alpha) \le H(\beta)$ первоначальной энтропии опыта $\beta$.

%\next

	При этом, если опыт $\beta$ не зависит от $\alpha$, то осуществление $\alpha$ не уменьшает энтропии $\beta$. Это значит, что $H(\beta|\alpha) = H(\beta)$. Если же результат $\alpha$ полностью предопределяет исход опыта $\beta$, то энтропия $\beta$ уменьшается до $0$: $H(\beta|\alpha) = 0$. Таким образом, разность \fbox{$I(\beta,\alpha) = H(\beta) - H(\beta|\alpha) (*)$}.

	Таким образом написанная разность указывает, насколько осуществление $\alpha$ уменьшает неопределённость $\beta$, т.е. как много мы узнаём об исходе опыта $\beta$, произведя измерение(наблюдение) в виде опыта $\alpha$. Эта разность $(*)$ называют количеством информации относительно опыта $\beta$, содержащейся в опыте $\alpha$. Таким образом, мы получаем возможность \term{численного измерения} информации. К примеру, в условиях задачи о болезненной реакции можно сказать, что используемая реакция в виде опыта $\alpha$ даёт информацию о заболевании в виде опыта $\beta$, равное $0.14-0.12 = 0.02$ бита. Эта цифра и оценивает пользу реакции.
	
	Соотношение между понятиями энтропии и информации напоминает соотношение между физическими понятиями потенциала и разности потенциалов. Энтропия есть абстрактная мера неопределённости. Ценность этого понятия в значительной мере заключается в том, что оно позволяет оценить влияние на опыт $\beta$ какого-либо другого опыта $\alpha$ как разность энтропий по формуле $(*)$.
	
	Подчеркнём также, что информация относительно опыта $\beta$, содержащаяся в опыте $\alpha$ представляет собой среднее значение (математическое ожидание) случайной величины $H(\beta) - H(\beta|A_i)$, связанной с отдельными исходами $A_i$ опыта $\alpha$.
	
	\task{Пример:} Задача о шарах и предварительной информации.
	
	% Конспектирование этих формул в реалтайме - просто угар \right)
	
	Пусть опыт $\beta$ состоит в извлечении одного шара из урны:
	
	$\beta$ : 1 шар из 5 чёрных и 10 белых. 

	А опыт $\alpha_k$ состоит в предварительном извлечении (без возвращения обратно) $K$ шаров:
	
	$\alpha_k$ : {\scriptsize $K$ шаров извлечено.}
	
	$H(\beta) = \; ?$

	$I(\beta,\alpha_1) = \; ?$
	
	$I(\beta,\alpha_2) = \; ?$

	$I(\beta,\alpha_{13}) = \; ?$

	$I(\beta,\alpha_{14}) = \; ?$

	Чему равна энтропия $H(\beta)$ и информация, содержащаяся в опыте $\alpha_1$? 
	
	\rtask{Решение:} 
	
	$
	  H(\beta) = - \frac{1}{3} \log \frac{1}{3} 
	             - \frac{2}{3} \log \frac{2}{3} 
	       \approx 0.92 \mbox{бита}. 
	$

	\strut

	$	
	  \; I(\beta,\alpha_1) = H(\beta) - H(\beta|\alpha_1)
	$

	$
	  \begin{aligned}
	  H(\beta|\alpha_1) = 
	&
	            \left[  p(A_1^{\mbox{\scriptsize чёр}}) * H(\beta|A_1^{\mbox{\scriptsize чёр}})
	           \right] 
	                  + 
	            \left[  p(A_1^{\mbox{\scriptsize бел}}) * H(\beta|A_1^{\mbox{\scriptsize бел}})
	           \right]
	     =
	\\
	     = 
	&
	       - \frac{1}{3} 
	           \left[
	             \underbrace{p(B^{\mbox{\scriptsize чёр}} | A_1^{\mbox{\scriptsize чёр}})}_{4/14} * \log \frac{4}{14} 
	           + \underbrace{p(B^{\mbox{\scriptsize бел}} | A_1^{\mbox{\scriptsize чёр}})}_{5/7} * \log \frac{5}{7}
	          \right]
	       -
	\\
	&
	       - \frac{2}{3}
	           \left[
	             \underbrace{p(B^{\mbox{\scriptsize чёр}} | A_1^{\mbox{\scriptsize бел}})}_{5/11} * \log \frac{5}{11}
	           + \underbrace{p(B^{\mbox{\scriptsize бел}} | A_1^{\mbox{\scriptsize бел}})}_{9/14} * \log \frac{9}{14}
	          \right] 
	  \approx 0.004 \mbox{бит}.
	  \end{aligned}	
	$
	
	\strut

	$
	  \; I(\beta|\alpha_2) = H(\beta) - H(\beta|\alpha_2)
	$ 
	
	$
	  \begin{aligned}
	  H(\beta|\alpha_2) = 
	& \;
	     % \left[
	              p(A_1^{\mbox{\scriptsize ч}} A_2^{\mbox{\scriptsize ч}}) 
	               * H(\beta | A_1^{\mbox{\scriptsize ч}} A_2^{\mbox{\scriptsize ч}})
	     % \right]
	     +
	     % \left[
	              p(A_1^{\mbox{\scriptsize ч}} A_2^{\mbox{\scriptsize б}})
	               * H(\beta | A_1^{\mbox{\scriptsize ч}} A_2^{\mbox{\scriptsize б}})
	     % \right]
	     +
	     % \left[
	              p(A_1^{\mbox{\scriptsize б}} A_2^{\mbox{\scriptsize б}})
	               * H(\beta | A_1^{\mbox{\scriptsize б}} A_2^{\mbox{\scriptsize б}})
	     % \right]
	     =	
	\\
	     = - \left\{ 
	                \vphantom{\underbrace{p(A_1)}_{3/13}}  
	                \frac{C^2_5}{C^2_{15}} 
	         \right.
	&
	         \left[  \underbrace{ p(B^{\mbox{\scriptsize чёр}} |
	                                A_1^{\mbox{\scriptsize чёр}} A_2^{\mbox{\scriptsize чёр}})}_{3/13}
	                  * \log \frac{3}{13}
	              +
	                 \underbrace{ p(B^{\mbox{\scriptsize бел}} |
	                                A_1^{\mbox{\scriptsize чёр}} A_1^{\mbox{\scriptsize чёр}})}_{10/13}
	                  * \log \frac{10}{13}
	         \right]
	       +
	\\
	       + \frac{C^1_{10} C^1_5}{C^2_{15}}
	&
                  \left[  \underbrace{ p(B^{\mbox{\scriptsize чёр}} |
                                         A_1^{\mbox{\scriptsize чёр}} A_2^{\mbox{\scriptsize бел}})}_{4/13}
                           * \log \frac{4}{13}
	               +
	                  \underbrace{ p(B^{\mbox{\scriptsize бел}} |
	                                 A_1^{\mbox{\scriptsize чёр}} A_2^{\mbox{\scriptsize бел}})}_{9/13}
	                   * \log \frac{9}{13}
	         \right]
	       +
	\\
	       + \frac{C^2_{10}}{C^2_{15}}
	&
	       \left.
                  \left[  \underbrace{ p(B^{\mbox{\scriptsize чёр}} |
                                         A_1^{\mbox{\scriptsize бел}} A_2^{\mbox{\scriptsize бел}})}_{5/13}
                           * \log \frac{5}{13}
	               +
	                  \underbrace{ p(B^{\mbox{\scriptsize бел}} |
	                                 A_1^{\mbox{\scriptsize бел}} A_2^{\mbox{\scriptsize бел}})}_{8/13}
	                   * \log \frac{8}{13}
	         \right]
	       \right\}
	    \approx 0.008 \mbox{бит}.
	\end{aligned}	
	$

	\strut \pagebreak[3]

	$
	   I(\beta,\alpha_{13}) = H(\beta) - H(\beta|\alpha_{13})
	$
	
	$H(\beta|\alpha_{13})$ - здесь неопределённость только в оставшихся двух шарах: они должны быть двух цветов, значит, мы взяли 4 чёрных и 9 белых шаров.

	
	$$ \hspace{-3em} %костыль
	  H(\beta|\alpha_{13}) = \frac{C^4_5 C^9_{10}}{C^{13}_{15}} (-) \left(  \frac{1}{2} \log \frac{1}{2} 
	                                                                    + \frac{1}{2}\log\frac{1}{2})
	                                                              \right)
	                     = - \frac { \frac{5!} {4!(5-4)!} \frac{10!} {9!(10-9)!} } 
	                               { \frac{15! }{13!(15-13)! * (-1)} }
	                     =   \frac{2*5*10}{14*15}
	                \approx 0.44 бит
	$$

	\strut

	$
	  I(\beta,\alpha_{14}) = \left[ H(\beta|\alpha_14) = 0 \right]
	               \approx 0.92 бит.
	$

\end{document}